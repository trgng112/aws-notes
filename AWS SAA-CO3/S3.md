- Main building blocks of AWS
- advertised as "infinite scaling" storage
- Many websites use S3 as a backbone
- Many AWS services use S3 as an integration as well

### Use cases
- Backup and storage
- Disaster recovery
- Archive
- Hybrid cloud storage
- Application hosting
- media hosting
- data lakes & big data analytics
- software delivery
- static website
- ![[Pasted image 20250726115747.png]]

### Buckets
- S3 allows people to store objects (files) in "buckets" (directories)
- buckets must have a globally unique name (across all regions all accounts)
- buckets are dined at the region levle
- **S3 looks like a global service but buckets are created in a region**
- Naming convention
	- No uppercase, no underscore
	- 3-63 characters long
	- Not an IP
	- Must start with lowercase letter or number
	- Must Not start with the prefix xn--
	- Must not end with the suffix -s3alias

### Objects
- Objects (files) have a Key
- the Key is the FULL path:
	- s3://my-bucket/**my_file.txt**
	- s3://my-bucket/**my_folder1/anothger_folder/my_file.txt**
- The key is composed of prefix + object name
	- s3://my-bucket/**my_folder1/another_folder/my_file.txt**
-  theres no concept of "directories" within buckets (although the UI will trick you to think otherwise)
- just keys with very long name that contains slashes
- Object values are the content of the body:
	- Max object size is 5TB
	- If uploading more than 5gb, must use "multi-part upload"
- Metadata (list of text key/value pairs - system or user metadata)
- Tags (unicode key/ value pair -up to 10) - useful for security / lifecycle
- Version ID (if versioning is enabled)


### Security
- User based
	- IAM policies - which API calls should be allowed for a specific user from IAM
- Resource-based
	- Bucket policies - bucket wide rules from the S3 console - allows cross account
	- Object Access Control LIst (ACL) - finer grain (can be disabled)
	- Bucket Access Control List (ACL) - less common (can be disabled)
- **Note: an IAM principal can access an S3 object if**
	- **The user IAM permissions ALLOW it OR the resource policy ALLOWS it**
	- **And There's no explicit DENY**
- Encryption: encrypt objects in Amazon S# using encryption keys

#### S3 Bucket Policies
- Json based policies
	- Resources: buckets and objects
	- Effect: Allow/ Deny
	- Actions: Set of API to Allow or Deny
	- Principal: The account or user to apply the policy to
- Use S3 bucket for policy to:
	- Grant public access to the bucket
	- Force objects to be encrypted at upload
	- Grant access to another account (Cross Account)
	- ![[Pasted image 20250726122705.png]]
- Example: 

	- ![[Pasted image 20250726122821.png]]
	- ![[Pasted image 20250726122831.png]]
	- ![[Pasted image 20250726122811.png]]
	- ![[Pasted image 20250726122910.png]]

### Static website hosting
- S3 can host static websites and have the accessible on the Internet 
- Website URL will be (depending on the region)
	- http://**bucket-name**.s3-websites-**aws-region**.amazonAWS.com
-  iF YOU GET 403 MAKE SURE THE BUKCET POLICY ALLOWS PUBLIC READS

### Versioning
- You can version your files in the S3
- enabled at the bucket level
- Same key overwrite will change the version: 1,2,3
- it is best practice to version your buckets
	- Protect against unintended deletes (restore a version)
	- easy rollback to previous version
- Notes:
	- Any file that is not versioned prior to enabling versioning will have version "null"
	- Suspending versioning does not delete the previous versions
### Replication (CRR & SRR)
- Must enable Versioning in source and destination buckets
- Cross- region replication (CRR)
- Same-Region Replication (SRR)
- Buckets can be different AWS accounts
- Copying is asynchronous
- Must give proper IAM permissions to S3
- Use cases:
	- CRR - compliance, lower latency access, replication across accounts
	- SRR - log aggregation, live replication between production and test accounts
- Notes:
	- After you enable replication, only new objects are replicated
	- optionally, you can replicate existing objects using **S3 Batch Replication**
		- Replicates existing objects and objects that failed replication
	- For DELETE operations
		- **Can replicate delete markers** from source to target (optional settings)
		- Deletions with a version ID are not replicated (to avoid malicious deletes)
	- **There is no chaining of replication** 
		- If bucket 1 has replication into bucket 2, which has replication into bucket 3
		- Then objects created in bucket 1 are not replicated to bucket 3

### S3 Storage Classes
- S3 Standard - General purpose
- Standard - Infrequent access (IA)
- One ZOne - Infrequent ACcess
- Glacier Instant Retrieval
- Glacier Flexible Retrieval
- Glacier Deep Archive
- Intelligent tiering
- Can move between classes manually or using S3 lifecycle configurations

#### Durability and availability
- Durability:
	- High durability (99.99999999999%, 11 9's) of objects across multiple AZ
	- if you store 10,000,000 objects with S3, you can on average expect to incur a loss of a single object once every 10,000 years
	- Same for all storage classes
- Availability:
	- Measures how readily available a service is
	- Varies depending on storage class
	- example: s3 standard has 99.99% availability = not available 53 minutes a year

#### S3 Standard - General purpose
- 99.99 availability
- used for frequently accessed data
- low latency and high throughput
- sustain 2 concurrent facility failures
- use cases: big data analytics, mobile, gaming applications, content distribution

#### Infrequent access
- For data that is less frequently accessed, but requires rapid access when needed 
- Lower cost than S3 standard
- S3 standard - infrequent Access (S3 standard IA)
	- 99.9% availability
	- Uses cases: Disaster recovery, backups
- S3 One zone - infrequent Access (S3 One Zone - IA)
  High durability (11 9's) in a single AZ; data lost when AZ is destroyed
	- 99.5 % availability
	- use cases: Storing secondary backup copies of an on-premise data, or data you can recreate

#### Glacier storage classes
- Low cost object storage meant for archiving/backup
- Pricing: price for storage + object retrieval cost
- Amazon S3 Glacier Instant Retrieval
	- Millisecond retrieval, great for data accessed once a quarter
	- Minimum storage duration of 90 days
- S3 Glacier Flexible Retrieval (formerly s3 glacier)
	- Expedited (1 to 5 minutes), Standard (3 to 5 hours) , bulk (5 to 12 hours) -free
	- Minimum storage duration of 90 days
- S3 Glacier Deep Archive - for long term storage
	- Standard (12 hrs), bulk (48 hrs)
	- Minimum storage duration of 180 days


#### S3 Intelligent - tiering
- Small monthly monitoring and auto-tiering fee
- moves object automatically between access Tiers based on usage
- There are no retrieval charges in S3 intelligent tiering
	- Frequent Access tier (automatic) default tier
	- Infrequent Access tier (automatic): objects not accessed for 30 days
	- Archive Instant Access Tier (automatic): objects not accessed from 90 days
	- Archive Access tier (optional): configurable from 90 days to 700+ days
	- Deep Archive Access tier (optional) config form 180 days to 700+ days

![[Pasted image 20250726132110.png]]